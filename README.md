## ML-Learning
机器学习-张伟楠 
个人学习及思考

- Common conceptual differences
  
  - Parametric vs Non-Parametric Models
  
  - Supervised Learning vs Unsupervised Learning vs Semi-supervised Learning

- KNN
  
  - The KNN algorithm completes the image classification problem of the MNIST dataset

  - Classification Effect of KNN on Gaussian Dataset (sklearn)

  - Use KNN to complete the regression mission - color style transfer

- Linear Regression
  
  - Linear regression (analytic solution) predicts house prices

  - Linear regression (gradient descent) predicts house prices(SGD VS GD)

  - Effect of learning rate on gradient decline

- Logistic Regression
   
   - Logistity's prediction and its model evaluation（AUC）

- Bilinear model 
  
  - Recommendations by Movie Ratings (Matrix Factorization（MF）)
  
  - Click prediction based on Factorization Machines (FM)

- Neural Networks and Multilayer Perceptrons 
  
  - Point classification problem based on multilayer perceptron

  - Point classification problem based on multilayer perceptron (pytorch)
  
- Convolutional neural networks
  
  - Image Classification Based on Convolutional Neural Network (CIFAR10 Dataset) (Alexnet Structure) (pytorch)

  - Color style transfer based on pre-trained Convolutional Neural Networks(VGG) (pytorch)

- Recurrent Neural Network
  
  - Sine function prediction based on Recurrent Neural Networks（GRU）(pytorch)

- Support Vector Machine
 
  - Simple linear data partitioning based on Support Vector Machines (SMO)
  
  - Nonlinear data partitioning based on Support Vector Machines (SMO)
  
  - Nonlinear data partitioning based on Support Vector Machines (SMO) (sklearn)

- Decision Tree
   
  - Survival classification of the Titanic based on decision trees（C4.5）

  - Survival Classification of Titanic Based on Decision Tree and Visualization of the Decision Tree(sklearn) (C4.5) (CART)

- Ensemble Learning and Gradient Boosting Decision Trees
     
 - Comparison of the classification effect of Bagging and Random Forest
    
 - Classification based on Stacking 
  
 - Compare the performance of different ensemble methods on Classification Prediction (AdaBoost,Bagging, AdaBoost, Random Forest) (stump).
 
 - Compare the performance of XGBoost with other models on Regression Prediction (XGBoost,KNN,Liner regression,Bagging,Random Forest,Stacking)

- K-means Clustering

  - Point clustering based on K-means

  - Point clustering based on K-means++

- Principal Component Analysis
  
  - PCA-Feature decomposition

- Probability Graph Models
  
  - Bayesian network
  
  - Markov network 

- Expectation-Maximization
  
  - EM for sinx

- Autoencoder（AE）






